{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "SEED = 69420\n",
    "DO_TRAINING = False\n",
    "EPOCHS_TO_TRAIN = 100\n",
    "BASE_MODEL = \"microsoft/resnet-50\"\n",
    "OUTPUT_MODEL_DIR = \"./models/resnet-pcb-ext-70-30/\"\n",
    "IMAGE_PROCESSOR_CLASS = transformers.AutoImageProcessor\n",
    "IMAGE_CLASSIFICATION_CLASS = transformers.ResNetForImageClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict\n",
    "\n",
    "ds = load_dataset(\"./datasets/training/\")\n",
    "testing_set = load_dataset(\"./datasets/testing/\")\n",
    "\n",
    "ds_train_devtest = ds['train'].train_test_split(test_size=0.2, seed=SEED)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': ds_train_devtest['train'],\n",
    "    'eval': ds_train_devtest['test'],\n",
    "    # 'test': ds_devtest['test']\n",
    "    'test': testing_set[\"train\"]\n",
    "})\n",
    "\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model_name = BASE_MODEL if DO_TRAINING else OUTPUT_MODEL_DIR\n",
    "except OSError:\n",
    "    model_name = BASE_MODEL\n",
    "\n",
    "processor = IMAGE_PROCESSOR_CLASS.from_pretrained(model_name)\n",
    "# processor(dataset[\"train\"][-1][\"image\"], return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(batch):\n",
    "    # Take a list of PIL images and turn them to pixel values\n",
    "    inputs = processor([x for x in batch['image']], return_tensors='pt')\n",
    "\n",
    "    # Don't forget to include the labels!\n",
    "    inputs['label'] = batch['label']\n",
    "    return inputs\n",
    "\n",
    "prepared_ds = dataset.with_transform(transform)\n",
    "# prepared_ds[\"eval\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        \"pixel_values\": torch.stack([x[\"pixel_values\"] for x in batch]),\n",
    "        \"labels\": torch.tensor([x[\"label\"] for x in batch]),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "def compute_metrics(p):\n",
    "    return metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset['train'].features['label'].names\n",
    "\n",
    "model = IMAGE_CLASSIFICATION_CLASS.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(labels),\n",
    "    id2label={str(i): c for i, c in enumerate(labels)},\n",
    "    label2id={c: str(i) for i, c in enumerate(labels)},\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=OUTPUT_MODEL_DIR,\n",
    "  per_device_train_batch_size=16,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=EPOCHS_TO_TRAIN,\n",
    "  # fp16=True,\n",
    "  save_steps=100,\n",
    "  eval_steps=100,\n",
    "  logging_steps=10,\n",
    "  learning_rate=2e-4,\n",
    "  save_total_limit=2,\n",
    "  remove_unused_columns=False,\n",
    "  push_to_hub=False,\n",
    "  report_to='tensorboard',\n",
    "  load_best_model_at_end=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=prepared_ds[\"train\"],\n",
    "    eval_dataset=prepared_ds[\"eval\"],\n",
    "    tokenizer=processor,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_TRAINING:\n",
    "    try:\n",
    "        train_results = trainer.train(resume_from_checkpoint=True)\n",
    "    except ValueError:\n",
    "        train_results = trainer.train()\n",
    "    trainer.save_model()\n",
    "    trainer.log_metrics(\"train\", train_results.metrics)\n",
    "    trainer.save_metrics(\"train\", train_results.metrics)\n",
    "    trainer.save_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate(prepared_ds['test'])\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = IMAGE_PROCESSOR_CLASS.from_pretrained(OUTPUT_MODEL_DIR)\n",
    "\n",
    "model = IMAGE_CLASSIFICATION_CLASS.from_pretrained(\n",
    "    OUTPUT_MODEL_DIR,\n",
    "    num_labels=len(labels),\n",
    "    id2label={str(i): c for i, c in enumerate(labels)},\n",
    "    label2id={c: str(i) for i, c in enumerate(labels)},\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "print(len(dataset[\"test\"]))\n",
    "# idx = 15\n",
    "# image = dataset[\"test\"][idx][\"image\"]\n",
    "# actual_label = labels[dataset[\"test\"][idx][\"label\"]]\n",
    "# inputs = processor(image, return_tensors=\"pt\")\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     logits = model(**inputs).logits\n",
    "\n",
    "# predicted_label = labels[logits.argmax(-1).item()]\n",
    "# labels[predicted_label]\n",
    "\n",
    "# display(image, f\"actual: {labels[actual_label]}\", f\"predicted: {labels[predicted_label]}\")\n",
    "# false_positives = 0\n",
    "# false_negatives = 0\n",
    "\n",
    "# for idx in range(len(dataset[\"test\"])):\n",
    "\n",
    "#     if actual_label == 'ok' != predicted_label:\n",
    "#         false_positives += 1\n",
    "#     elif actual_label == 'defective' != predicted_label:\n",
    "#         false_negatives += 1\n",
    "\n",
    "# print(f'false_positives: {false_positives}')\n",
    "# print(f'false_negatives: {false_negatives}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "for idx, item in enumerate(dataset[\"test\"]):\n",
    "    image = item[\"image\"]\n",
    "    # actual_label = labels[dataset[\"test\"][idx][\"label\"]]\n",
    "    actual_label = item[\"label\"]\n",
    "    inputs = processor(image, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    # predicted_label = labels[logits.argmax(-1).item()]\n",
    "    predicted_label = logits.argmax(-1).item()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
